
Loading the datasets
`low_cpu_mem_usage` was None, now set to True since model is quantized.






Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [34:38<00:00, 346.37s/it]
/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Detected kernel version 5.4.204, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs



















































































  1%|          | 99/10000 [05:09<9:07:48,  3.32s/it]





































































































  2%|â–         | 200/10000 [10:22<8:12:15,  3.01s/it]




































































































  3%|â–Ž         | 300/10000 [15:39<8:27:30,  3.14s/it]



































































































  4%|â–         | 399/10000 [20:47<8:06:47,  3.04s/it]




































































































  5%|â–         | 499/10000 [25:59<8:04:27,  3.06s/it]
  5%|â–Œ         | 500/10000 [26:02<7:57:51,  3.02s/it]








































 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [01:20<00:01,  2.35it/s]




































































































  6%|â–Œ         | 599/10000 [32:35<8:00:23,  3.07s/it]




































































































  7%|â–‹         | 699/10000 [37:43<7:53:42,  3.06s/it]





































































































  8%|â–Š         | 800/10000 [42:58<8:59:09,  3.52s/it]



































































































  9%|â–‰         | 899/10000 [48:02<8:15:34,  3.27s/it]




































































































 10%|â–‰         | 999/10000 [53:17<7:28:49,  2.99s/it]
 10%|â–ˆ         | 1000/10000 [53:20<7:29:35,  3.00s/it]








































100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [01:21<00:00,  2.35it/s]





































































































 11%|â–ˆ         | 1100/10000 [59:56<7:20:09,  2.97s/it]



































































































 12%|â–ˆâ–        | 1199/10000 [1:04:58<7:18:02,  2.99s/it]




































































































 13%|â–ˆâ–Ž        | 1299/10000 [1:10:07<7:33:02,  3.12s/it]





































































































 14%|â–ˆâ–        | 1400/10000 [1:15:21<7:31:06,  3.15s/it]



































































































 15%|â–ˆâ–Œ        | 1500/10000 [1:20:33<7:28:37,  3.17s/it]
  0%|          | 0/200 [00:00<?, ?it/s]









































 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [01:20<00:01,  2.36it/s]




































































































 16%|â–ˆâ–Œ        | 1600/10000 [1:27:12<7:03:00,  3.02s/it]




































































































 17%|â–ˆâ–‹        | 1700/10000 [1:32:21<7:06:19,  3.08s/it]



































































































 18%|â–ˆâ–Š        | 1799/10000 [1:37:28<6:45:05,  2.96s/it]




































































































 19%|â–ˆâ–‰        | 1899/10000 [1:42:40<7:12:06,  3.20s/it]




































































































 20%|â–ˆâ–‰        | 1999/10000 [1:47:52<6:54:49,  3.11s/it]
 20%|â–ˆâ–ˆ        | 2000/10000 [1:47:55<6:50:48,  3.08s/it]








































100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [01:21<00:00,  2.35it/s]

{'eval_loss': 3.0375261306762695, 'eval_runtime': 82.2061, 'eval_samples_per_second': 4.866, 'eval_steps_per_second': 2.433, 'epoch': 0.3}

 20%|â–ˆâ–ˆ        | 2000/10000 [1:49:26<7:17:45,  3.28s/it]
Training completed. Model saved. at  /l/users/abdelrahman.sadallah/nadi/core42/jais-13b-chat