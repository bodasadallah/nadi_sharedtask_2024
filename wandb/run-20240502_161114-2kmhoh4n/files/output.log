
wandb: Network error resolved after 0:01:19.285979, resuming normal operation.
Loading the datasets
`low_cpu_mem_usage` was None, now set to True since model is quantized.





Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [12:25<00:00, 124.19s/it]
/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/training_args.py:1463: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Detected kernel version 5.4.204, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
max_steps is given, it will override any value given in num_train_epochs






































  0%|          | 99/100000 [02:08<33:35:52,  1.21s/it]






























































  0%|          | 199/100000 [04:14<42:26:31,  1.53s/it]




























































  0%|          | 299/100000 [06:18<31:40:47,  1.14s/it]






























































  0%|          | 398/100000 [08:23<31:56:29,  1.15s/it]


































































  0%|          | 499/100000 [10:35<37:45:49,  1.37s/it]

  0%|          | 500/100000 [10:37<36:53:58,  1.34s/it]































 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [01:03<00:02,  1.39it/s]































































  1%|          | 599/100000 [13:53<34:34:46,  1.25s/it]































































  1%|          | 699/100000 [16:01<34:34:24,  1.25s/it]





















































