{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545f3a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 23:30:48.319980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 23:30:48.320138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 23:30:48.321361: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 23:30:48.328213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 23:30:49.460928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/abdelrahman.sadallah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import HfArgumentParser, Seq2SeqTrainingArguments,EarlyStoppingCallback\n",
    "\n",
    "import logging\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, Optional\n",
    "from datasets import load_dataset, concatenate_datasets,Value\n",
    "import numpy as np\n",
    "from typing import Union, Optional\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction, GlueDataset, AutoModel\n",
    "from transformers import GlueDataTrainingArguments as DataTrainingArguments\n",
    "\n",
    "from arguments import ModelArguments, DataArguments\n",
    "import wandb\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "logger = logging.getLogger(__name__)\n",
    "from transformers import (RobertaForMultipleChoice, RobertaTokenizer, Trainer,\n",
    "                          TrainingArguments, XLMRobertaForMultipleChoice,\n",
    "                          XLMRobertaTokenizer)\n",
    "\n",
    "import pathlib\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "\n",
    "\n",
    "from utils import *\n",
    "import numpy as np\n",
    "from peft import PeftModel    \n",
    "import logging\n",
    "import os\n",
    "\n",
    "# import evaluate \n",
    "from evaluate import load \n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def split_sequence(sequence, chunk_size):\n",
    "    chunks=[]\n",
    "    for i in range(0, len(sequence), chunk_size):\n",
    "        chunks.append(sequence[i: i + chunk_size])\n",
    "    return chunks\n",
    "\t\t\n",
    "\n",
    "def calc_results(prediction, truth, save_file, chunk_size=100):\n",
    "    \n",
    "\n",
    "    global bleu_score\n",
    "    \n",
    "    if (len(truth) != len(prediction)):\n",
    "        print (\"both files must have same number of instances\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "    truth_chunks= split_sequence(truth, chunk_size)\n",
    "\n",
    "    truth_Egyptain=truth_chunks[0]\n",
    "    truth_Emirati=truth_chunks[1]\n",
    "    truth_Jordanian=truth_chunks[2]\n",
    "    truth_Palestinian=truth_chunks[3]\n",
    "\n",
    "    prediction_chunks= split_sequence(prediction, chunk_size)\n",
    "\n",
    "    prediction_Egyptain=prediction_chunks[0]\n",
    "    prediction_Emirati=prediction_chunks[1]\n",
    "    prediction_Jordanian=prediction_chunks[2]\n",
    "    prediction_Palestinian=prediction_chunks[3]\n",
    "\n",
    "    ### get scores\n",
    "    results_Egyptain = bleu_score.compute(predictions=prediction_Egyptain, references=truth_Egyptain)\n",
    "    results_Emirati = bleu_score.compute(predictions=prediction_Emirati, references=truth_Emirati)\n",
    "    results_Jordanian = bleu_score.compute(predictions=prediction_Jordanian, references=truth_Jordanian)\n",
    "    results_Palestinian = bleu_score.compute(predictions=prediction_Palestinian, references=truth_Palestinian)\n",
    "    overall_results = bleu_score.compute(predictions=prediction, references=truth)\n",
    "\n",
    "    #write to a text file\n",
    "    print('Scores:')\n",
    "    scores = {\n",
    "            'Overall': overall_results['bleu']*100,\n",
    "            'Egyptain': results_Egyptain['bleu']*100,\n",
    "            'Emirati': results_Emirati['bleu']*100,\n",
    "            'Jordanian': results_Jordanian['bleu']*100,\n",
    "            'Palestinian': results_Palestinian['bleu']*100, \n",
    "            }\n",
    "    print(scores)\n",
    "\n",
    "    with open(save_file, 'w') as score_file:\n",
    "        score_file.write(\"Overall: %0.12f\\n\" % scores[\"Overall\"])\n",
    "        score_file.write(\"Egyptain: %0.12f\\n\" % scores[\"Egyptain\"])\n",
    "        score_file.write(\"Emirati: %0.12f\\n\" % scores[\"Emirati\"])\n",
    "        score_file.write(\"Jordanian: %0.12f\\n\" % scores[\"Jordanian\"])\n",
    "        score_file.write(\"Palestinian: %0.12f\\n\" % scores[\"Palestinian\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212741f9-d70f-41d8-a2ce-e80456a7491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_name_or_path='core42/jais-13b'\n",
    "model_name_or_path='core42/jais-13b-chat'\n",
    "\n",
    "\n",
    "dataset = 'boda/nadi2024'\n",
    "prompt_key=\"prompt\"\n",
    "chunk_size =500 \n",
    "split=\"test\"\n",
    "per_device_eval_batch_size=4\n",
    "save_file='outputs/jais_val'\n",
    "# checkpoint_path='/l/users/abdelrahman.sadallah/nadi/core42/jais-13b/best/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50218e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the   test datasets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bleu_score = load(\"bleu\")\n",
    "\n",
    "\n",
    "print(f\"Loading the   {split} datasets\")\n",
    "dataset = get_dataset(\n",
    "    dataset_name = dataset,\n",
    "    split=split,\n",
    "    field=prompt_key)\n",
    "\n",
    "\n",
    "save_file = save_file\n",
    "\n",
    "\n",
    "val_dataloader = DataLoader(dataset, batch_size=per_device_eval_batch_size, shuffle=False)  \n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fa5f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b5a4bfdae54564a9328b86fa09ccdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    trust_remote_code=True,\n",
    "    return_dict=True,\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0714a-ad8a-46ac-8dc0-a1b479a73b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /l/users/abdelrahman.sadallah/nadi/core42/jais-13b-chat/best/\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path= '/l/users/abdelrahman.sadallah/nadi/core42/jais-13b-chat/best/'\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    # bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "if checkpoint_path:\n",
    "    print(f'Loading model from {checkpoint_path}')\n",
    "    adapter_checkpoint  = checkpoint_path\n",
    "    model = PeftModel.from_pretrained(model, adapter_checkpoint,quantization_config=bnb_config)\n",
    "\n",
    "else:\n",
    "    print(f'Loading Base Model {model_name_or_path}')\n",
    "\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "# Define PAD Token = BOS Token\n",
    "model.config.pad_token_id = model.config.bos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d1324a0-3de5-424e-be14-60be2f2af3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f98c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(prompts, tokenizer, model):\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    outs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for p in prompts:\n",
    "            \n",
    "            encoding = tokenizer(p, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "    \n",
    "            try:\n",
    "                outputs = model.generate(\n",
    "                    **encoding,\n",
    "                    max_new_tokens=256,\n",
    "                    do_sample=False,\n",
    "                    # top_p = 0.9,\n",
    "                    repetition_penalty=1.4,\n",
    "                    # temperature=0.9,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "                answer_tokens = outputs[:, encoding.input_ids.shape[1] :]\n",
    "                output_text = tokenizer.batch_decode(answer_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "                # print(output_text)\n",
    "            except:\n",
    "                invalid += 1\n",
    "                output_text = ['']\n",
    "        \n",
    "            outs.append(output_text[0])\n",
    "\n",
    "\n",
    "    return outs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c3069c-ee3b-447f-9af7-245aa4a445f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['source', 'target', 'dialect', 'prompt'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e6b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                                                      | 1/500 [00:15<2:06:05, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                                                      | 2/500 [00:23<1:32:56, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                                                                                      | 3/500 [00:32<1:24:35, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                                                                     | 4/500 [00:41<1:21:06,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▌                                                                                                                                                     | 5/500 [00:50<1:17:26,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▊                                                                                                                                                     | 6/500 [00:58<1:14:29,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|██                                                                                                                                                     | 7/500 [01:06<1:09:39,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▍                                                                                                                                                    | 8/500 [01:14<1:07:52,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▋                                                                                                                                                    | 9/500 [01:25<1:14:47,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███                                                                                                                                                   | 10/500 [01:35<1:18:00,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▎                                                                                                                                                  | 11/500 [01:48<1:25:51, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▌                                                                                                                                                  | 12/500 [01:58<1:25:03, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▉                                                                                                                                                  | 13/500 [02:06<1:19:34,  9.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▏                                                                                                                                                 | 14/500 [02:16<1:17:55,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▌                                                                                                                                                 | 15/500 [02:24<1:14:50,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|████▊                                                                                                                                                 | 16/500 [02:32<1:12:15,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█████                                                                                                                                                 | 17/500 [02:42<1:13:32,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▍                                                                                                                                                | 18/500 [02:52<1:15:08,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▋                                                                                                                                                | 19/500 [02:59<1:10:13,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████                                                                                                                                                | 20/500 [03:06<1:06:43,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▎                                                                                                                                               | 21/500 [03:19<1:15:53,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██████▌                                                                                                                                               | 22/500 [03:29<1:18:15,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██████▉                                                                                                                                               | 23/500 [03:41<1:23:46, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▏                                                                                                                                              | 24/500 [03:48<1:15:11,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▌                                                                                                                                              | 25/500 [03:56<1:10:35,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███████▊                                                                                                                                              | 26/500 [04:04<1:07:54,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████████                                                                                                                                              | 27/500 [04:19<1:22:29, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▍                                                                                                                                             | 28/500 [04:29<1:23:10, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████████▋                                                                                                                                             | 29/500 [04:41<1:24:16, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████                                                                                                                                             | 30/500 [04:49<1:18:44, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▎                                                                                                                                            | 31/500 [04:59<1:19:00, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████████▌                                                                                                                                            | 32/500 [05:07<1:14:22,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████████▉                                                                                                                                            | 33/500 [05:17<1:14:28,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▏                                                                                                                                           | 34/500 [05:27<1:14:41,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▌                                                                                                                                           | 35/500 [05:39<1:19:17, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████████▊                                                                                                                                           | 36/500 [05:51<1:23:44, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████████                                                                                                                                           | 37/500 [06:05<1:31:13, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████▍                                                                                                                                          | 38/500 [06:14<1:25:20, 11.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████████▋                                                                                                                                          | 39/500 [06:25<1:23:53, 10.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████                                                                                                                                          | 40/500 [06:32<1:14:44,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▎                                                                                                                                         | 41/500 [06:48<1:29:43, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████████▌                                                                                                                                         | 42/500 [06:55<1:18:57, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████████▉                                                                                                                                         | 43/500 [07:03<1:13:15,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▏                                                                                                                                        | 44/500 [07:12<1:11:15,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|█████████████▌                                                                                                                                        | 45/500 [07:25<1:18:26, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for batch in tqdm(val_dataloader):\n",
    "\n",
    "    prompts = batch['prompt']\n",
    "    ans = []\n",
    "\n",
    "    labels.extend(batch['target'])\n",
    "\n",
    "    output_text = inference(prompts=prompts, tokenizer=tokenizer, model=model)\n",
    "\n",
    "    predictions.extend(output_text)\n",
    "\n",
    "    print(len(predictions))\n",
    "    # break\n",
    "assert (len(predictions) == len(labels))\n",
    "\n",
    "save_file =   save_file + '_results.txt'\n",
    "\n",
    "preds_file = save_file + '_predictions.txt'\n",
    "\n",
    "with open(preds_file, 'w') as f:\n",
    "    for item in predictions:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n",
    "calc_results(predictions, labels, save_file,chunk_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae57c04-2018-4a7d-a2d8-e0bfac6b0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions) , invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29acb557-1303-40ad-b052-097a6c744ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "model.to(device)\n",
    "def get_response(text,tokenizer=tokenizer,model=model):\n",
    "    \n",
    "\n",
    "    \n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\") # .input_ids\n",
    "    inputs = input_ids.to(device)\n",
    "    # input_len = inputs.shape[-1]\n",
    "    generate_ids = model.generate(\n",
    "        **inputs,\n",
    "        top_p=0.5,\n",
    "        temperature=0.5,\n",
    "         max_new_tokens=32,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    \n",
    "    answer_tokens = generate_ids[:, inputs.input_ids.shape[1] :]\n",
    "    response = tokenizer.batch_decode(\n",
    "        answer_tokens, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "    return response\n",
    "\n",
    "\n",
    "# text = '''.فيما يلي جملة باللهجة العربية المصرية. يرجى ترجمتها إلى اللغة العربية الفصحى الحديثة\n",
    "# طّلع الرجالة اللي انت عايزهم من الجراج و قطاع النقل يمشّطوا المناطق دي لحد ما يلاقوهم\n",
    "# '''\n",
    "\n",
    "text='''The following is a sentence in Egyptain Arabic dialect. Please translate it to Modern Standard Arabic (MSA).\n",
    "طّلع الرجالة اللي انت عايزهم من الجراج و قطاع النقل يمشّطوا المناطق دي لحد ما يلاقوهم.\n",
    "'''\n",
    "text = dataset['prompt'][0]\n",
    "print(get_response(text))\n",
    "\n",
    "# text = \"The capital of UAE is\"\n",
    "# print(get_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fc20e-a9f2-4303-a193-c982d8a49d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b546f23-cd9c-46b4-92f5-e30cf5dd239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['prompt']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
